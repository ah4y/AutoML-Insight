# ğŸŒ Remote Execution Guide

AutoML-Insight now supports training models on remote servers with **unlimited RAM and GPU power**!

## ğŸ¯ Why Remote Execution?

**Problem**: Your dataset has 150,000 samples Ã— 361,000 features = **403 GB RAM required** ğŸ˜±

**Solution**: Train on cloud servers with enough resources! â˜ï¸

---

## ğŸš€ Quick Start (3 Options)

### Option 1: ğŸŒ Remote Jupyter Server (Recommended)

**Use Case**: You have access to a powerful server with Jupyter

**Steps**:
1. Start Jupyter on your server: `jupyter notebook --ip=0.0.0.0 --port=8888`
2. In AutoML-Insight, select "ğŸŒ Remote Jupyter Server"
3. Enter server URL (e.g., `http://192.168.1.100:8888`)
4. Enter token (if required)
5. Click "ğŸ”— Connect"
6. Click "ğŸš€ Run on Remote Server"
7. Watch real-time progress!

**Advantages**:
- âœ… Direct connection
- âœ… Real-time logs
- âœ… Automatic result retrieval
- âœ… Works with any Jupyter server

---

### Option 2: â˜ï¸ Google Colab (Free GPU!)

**Use Case**: You don't have a server but want free GPU power

**Steps**:
1. Get free ngrok token from [ngrok.com](https://ngrok.com) (takes 30 seconds)
2. In AutoML-Insight, select "â˜ï¸ Google Colab Setup"
3. Enter your ngrok token
4. Click "ğŸ“‹ Show Setup Instructions"
5. Copy the setup code
6. Open [Google Colab](https://colab.research.google.com)
7. Paste and run the code
8. Copy the public URL (e.g., `https://abc123.ngrok.io`)
9. Paste URL in AutoML-Insight
10. Click "ğŸ”— Connect"
11. Click "ğŸš€ Run on Google Colab"

**Free Resources**:
- ğŸ“Š **12 GB RAM**
- ğŸ® **T4 GPU** (16 GB VRAM)
- â±ï¸ **12 hours** continuous runtime
- ğŸ†“ **100% Free**

**Advantages**:
- âœ… No setup required
- âœ… Free GPU access
- âœ… Good for datasets up to ~50K features
- âœ… No credit card needed

---

### Option 3: ğŸ“Š Kaggle Kernels (More Power)

**Use Case**: You need even more resources than Colab

**Free Resources**:
- ğŸ“Š **30 GB RAM** (2.5x more than Colab!)
- ğŸ® **P100 GPU** (16 GB VRAM)
- â±ï¸ **9 hours** runtime per session

**Note**: Direct integration coming soon! For now, use Option 1 or 2.

---

## ğŸ“Š How It Works

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Browser  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  AutoML-Insight â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Remote Jupyter  â”‚
â”‚   (Streamlit)   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Dashboard     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     Server      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                               â”‚
                                                               â–¼
                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                         â”‚  Training   â”‚
                                                         â”‚  (4 models) â”‚
                                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Happens:

1. **Upload**: Dataset sent to remote server (compressed)
2. **Install**: Dependencies installed automatically (`pip install`)
3. **Train**: Models trained in parallel on remote resources
4. **Stream**: Real-time logs streamed back to your browser
5. **Download**: Results automatically retrieved

---

## ğŸ”’ Security

### Your Data:
- âœ… Encrypted in transit (HTTPS/WSS)
- âœ… Deleted after training
- âœ… Never stored permanently
- âœ… Only you have access (token-protected)

### Tokens:
- ğŸ”‘ Stored only in your browser session
- ğŸ”‘ Never sent to our servers
- ğŸ”‘ Can use temporary tokens
- ğŸ”‘ Revoke anytime

---

## ğŸ’¡ Pro Tips

### For Large Datasets:

1. **Use Feature Selection**: Set `max_features=1000` to limit memory
2. **Colab Pro+**: Get 51 GB RAM for $49.99/month
3. **AWS SageMaker**: For production workloads
4. **Kaggle Kernels**: Free 30 GB RAM alternative

### Optimizing Performance:

```python
# In remote execution, these optimizations are applied automatically:
- Feature pre-selection (variance-based)
- Memory-efficient data types
- Sparse matrix support
- Chunked processing
```

### Troubleshooting:

| Problem | Solution |
|---------|----------|
| Connection timeout | Check firewall, use ngrok |
| Out of memory | Reduce max_features, use Kaggle |
| Slow training | Enable GPU in Colab runtime |
| Token error | Regenerate token, check URL |

---

## ğŸ“ Example: Training on Colab

### Step-by-Step with Screenshots:

**1. Get Ngrok Token** (1 minute)
- Go to [ngrok.com](https://ngrok.com)
- Sign up (free)
- Copy your token

**2. Configure AutoML-Insight**
```
1. Upload your dataset
2. Select "â˜ï¸ Google Colab Setup"
3. Paste ngrok token
4. Click "ğŸ“‹ Show Setup Instructions"
```

**3. Setup Colab** (2 minutes)
```python
# This code is auto-generated for you!
!pip install -q pyngrok
from pyngrok import ngrok
ngrok.set_auth_token("YOUR_TOKEN")
!jupyter notebook --port=8888 &
public_url = ngrok.connect(8888)
print(public_url)  # Copy this!
```

**4. Connect & Train**
```
1. Copy the public URL from Colab
2. Paste in AutoML-Insight sidebar
3. Click "ğŸ”— Connect"
4. Click "ğŸš€ Run on Google Colab"
5. Watch progress in real-time!
```

**5. Get Results** (Automatic!)
```
âœ… Training completed!
ğŸ“Š Results displayed automatically
ğŸ“¥ Download detailed report
```

---

## ğŸ“ˆ Performance Comparison

| Dataset Size | Local (8 GB) | Colab Free | Kaggle | Cloud VM |
|--------------|--------------|------------|---------|----------|
| 10K Ã— 100    | âœ… 2 min     | âœ… 1 min   | âœ… 1 min | âœ… 30 sec |
| 50K Ã— 1K     | âš ï¸ 15 min    | âœ… 5 min   | âœ… 3 min | âœ… 1 min |
| 150K Ã— 10K   | âŒ OOM       | âœ… 20 min  | âœ… 10 min | âœ… 5 min |
| 150K Ã— 361K  | âŒ OOM       | âŒ OOM     | âš ï¸ 2 hrs | âœ… 30 min |

**Legend**: âœ… Works well | âš ï¸ Possible | âŒ Out of Memory

---

## ğŸ†˜ Need Help?

### Common Issues:

**Q: "Connection failed"**
A: Check URL format, ensure Jupyter is running, verify token

**Q: "Out of memory on Colab"**
A: Reduce max_features, use Kaggle instead, or enable feature pre-selection

**Q: "Training is slow"**
A: Enable GPU in Colab (Runtime â†’ Change runtime type â†’ T4 GPU)

**Q: "Can I use my own cloud VM?"**
A: Yes! Just run Jupyter and connect via "Remote Jupyter Server"

---

## ğŸ”® Coming Soon

- [ ] Direct Kaggle Kernels integration
- [ ] AWS SageMaker support
- [ ] Azure ML integration
- [ ] Multi-server parallel training
- [ ] Auto-scaling based on dataset size
- [ ] Cost estimation for cloud providers

---

## ğŸ“š Additional Resources

- **Ngrok Docs**: [ngrok.com/docs](https://ngrok.com/docs)
- **Colab Guide**: [colab.research.google.com](https://colab.research.google.com)
- **Kaggle API**: [kaggle.com/docs/api](https://kaggle.com/docs/api)
- **Jupyter Server**: [jupyter-server.readthedocs.io](https://jupyter-server.readthedocs.io)

---

**Ready to train on unlimited resources?** ğŸš€

Start by selecting your execution mode in the sidebar!
