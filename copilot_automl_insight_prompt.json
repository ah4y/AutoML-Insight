{
  "goal": "Build a professional, research-ready AutoML prototype named 'AutoML-Insight' in VS Code. The system automatically profiles datasets, trains and compares advanced ML models (ANNs, Ensembles, Clustering), visualizes metrics, and recommends the best approach using meta-learning and pattern recognition. It must include a fully working demo (Iris/Wine), Streamlit dashboard, and exportable analytical report. The codebase must reflect production-level structure, reusability, and explainability standards.",
  "principles": {
    "architecture": "Follow modular OOP principles (clear interfaces, reusable components).",
    "reproducibility": "Use deterministic seeds and YAML configs. Enable reproducible runs and JSON-logged results.",
    "transparency": "Include SHAP-based explanations, feature importance charts, and calibrated metrics with CI bars.",
    "performance": "Vectorized operations via NumPy/Pandas, efficient caching, and optional GPU acceleration for PyTorch MLP.",
    "usability": "Streamlit UI with tabs, interactive Plotly visualizations, and one-click PDF report export."
  },
  "instructions": [
    {
      "step": "Directory Layout",
      "details": [
        "Create folders: app/, core/, experiments/, data/, results/, tests/, utils/.",
        "core/: data_profile.py, preprocess.py, models_supervised.py, models_clustering.py, tuning.py, evaluate_cls.py, evaluate_clu.py, visualize.py, explain.py, meta_selector.py, ensemble.py.",
        "app/: main.py (Streamlit entry), ui_dashboard.py, report_builder.py, config.yaml.",
        "experiments/: run_experiment.py, configs/default.yaml.",
        "utils/: logging_utils.py, metrics_utils.py, seed_utils.py.",
        "Add requirements.txt, README.md, .gitignore, LICENSE, and setup.py for packaging."
      ]
    },
    {
      "step": "Dependencies and Environment",
      "details": [
        "Python 3.11+",
        "Core libs: pandas, numpy, scikit-learn, xgboost, torch, shap, matplotlib, seaborn, plotly, umap-learn, scipy, statsmodels, streamlit, tqdm, pyyaml, reportlab, weasyprint, optuna, joblib.",
        "Dev tools: black, flake8, pytest, pre-commit hooks for linting and testing."
      ]
    },
    {
      "step": "Core Components",
      "details": [
        "data_profile.py: Compute meta-features: rows, columns, missing ratio, type ratio, skewness, kurtosis, class entropy, feature correlation, linear separability score.",
        "preprocess.py: Robust preprocessing pipeline using sklearn ColumnTransformer (OneHotEncoder, StandardScaler, SimpleImputer).",
        "models_supervised.py: Classes for LogisticRegression, LinearSVM, RBF-SVM, kNN, RandomForest, XGBoost, and a PyTorch-based MLP with early stopping, dropout, and learning rate scheduling.",
        "models_clustering.py: KMeans with elbow/silhouette auto-K, GMM with BIC/AIC, DBSCAN (auto eps), Agglomerative, Spectral.",
        "tuning.py: Nested CV with Optuna-based parameter tuning for efficiency.",
        "evaluate_cls.py: Compute nested 5x3 CV with Accuracy, Macro-F1, ROC-AUC, LogLoss, Brier, CI intervals; include McNemar and Wilcoxon tests for statistical significance.",
        "evaluate_clu.py: Compute Silhouette, Davies–Bouldin, Calinski–Harabasz, and cluster stability metrics.",
        "meta_selector.py: Meta-learning engine that uses GradientBoost or shallow MLP to map dataset meta-features to model families. Include heuristic rules for fallback.",
        "ensemble.py: Weighted ensemble and stacking with calibration; weight ∝ score / variance.",
        "visualize.py: Plotly dashboards for leaderboard, ROC, PR, calibration, confusion, SHAP, feature importances, cluster diagnostics (Elbow, Silhouette, UMAP).",
        "explain.py: SHAP, PDP, and permutation importance wrappers; auto-generate explanation plots per model."
      ]
    },
    {
      "step": "Streamlit App",
      "details": [
        "Sidebar: Dataset uploader, target selector, task type (Classification / Clustering), 'Run AutoML' button, 'Demo Mode' toggle.",
        "Tabs:",
        "Data Overview — profile metrics, missingness plot, correlation heatmap.",
        "Supervised Models — leaderboard with CI bars, ROC/PR plots, calibration charts, per-class F1 breakdown.",
        "Clustering — silhouette trends, elbow chart, 2D UMAP projection.",
        "Explainability — SHAP summary, feature impact plots.",
        "Recommendation — model summary, p-values, metrics, rationale bullets, 'Download Report' button.",
        "Demo Mode: auto-run on Iris and Wine datasets, show combined comparison dashboard."
      ]
    },
    {
      "step": "PDF Reporting",
      "details": [
        "report_builder.py: Generate PDF (via ReportLab/WeasyPrint) summarizing: dataset info, model leaderboard (with CI), statistical tests, top plots (ROC/PR, calibration, importances), final recommendation, and appendix with run metadata.",
        "Export path: results/reports/AutoML_Report_<timestamp>.pdf.",
        "Provide Streamlit download link."
      ]
    },
    {
      "step": "Data and Demo Integration",
      "details": [
        "Use sklearn.datasets to pre-load Iris and Wine datasets; save them in data/demo_iris.csv and data/demo_wine.csv.",
        "If user uploads no file, default to Iris dataset; in Demo Mode, compare both datasets.",
        "Store all run artifacts (metrics.json, plots/, report.pdf) in results/runs/<timestamp>/."
      ]
    },
    {
      "step": "Advanced Engineering Enhancements",
      "details": [
        "Implement logging (utils/logging_utils.py) using Python logging with timestamps, levels, and rotating file handlers.",
        "Include seed control via utils/seed_utils.py for deterministic experiments.",
        "Add configuration management via YAML and argparse for reproducible runs.",
        "Use joblib caching for re-used model training steps.",
        "Enable optional GPU detection (torch.cuda.is_available()).",
        "Include profiling hooks (tqdm progress bars, runtime logs)."
      ]
    },
    {
      "step": "Testing and CI",
      "details": [
        "tests/: unit + integration tests covering preprocessing, training, evaluation, visualization, and meta-selector.",
        "Add CI readiness: pytest workflow + flake8 linting config.",
        "README.md: include architecture diagram, setup guide, demo screenshots, and academic references for ensemble learning and clustering evaluation."
      ]
    }
  ],
  "output": {
    "deliverables": [
      "Full VS Code Python project (AutoML-Insight) with modular architecture.",
      "Interactive Streamlit dashboard supporting supervised and unsupervised workflows.",
      "Meta-learning based recommendation engine with visualization justification.",
      "Demo datasets (Iris/Wine) pre-integrated and runnable out-of-the-box.",
      "Automated PDF report summarizing results, stats, and reasoning.",
      "Well-documented, linted, and testable codebase ready for academic or professional presentation."
    ]
  }
}
